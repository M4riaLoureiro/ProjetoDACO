\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[font=footnotesize]{caption}
\usepackage{fancyhdr}
\usepackage[document]{ragged2e}
\usepackage[super]{nth}
\usepackage{parskip}
\usepackage{hyperref}
\usepackage{capt-of}
\pagestyle{headings}
\setlength{\parindent}{0pt}

\textwidth = 460pt
\oddsidemargin = 10pt
\topmargin = -60pt
\textheight = 690pt

\title{\textbf{Analysis of Voice Data towards Biometric Identification:\\ Gender, Age and Identity Classification}\par Computer-Aided Diagnostics}
\author{
João Carlos Ramos Gonçalves de Matos – up201704111\\
Maria Jorge Miranda Loureiro – up201704188\\
Maria Manuel Domingos Carvalho – up201706990\\
}
\date{\nth{15} January 2021}

\begin{document}

\maketitle
\thispagestyle{empty} 

\justify
\normalsize
\setlength{\parindent}{0pt}

\textbf{\emph{Abstract - Add abstract} }
\vspace{2mm}

\textbf{\emph{Keywords - Add keywords (maybe 4/5) } }
\vspace{2mm}

\textbf{I. Introduction}\par

\vspace{2mm}
\textbf{II. Data Preparation }\par

\vspace{2mm}
\textbf{ A. Feature Extraction }\par
To train machine learning models to classify gender, age and identity, voice signal features can be used as the training set of these models. Taking into account the different features considered relevant in the literature [1,2] , a set of signal features were chosen and extracted from all the utterances in the database (Table 1). The pyAudioAnalysis (version 0.3.6) python library was used to extract all audio features.

At first, each model was trained with the complete set of features. Then, to reduce the dimension of the dataset, remove redundant information and reduce running cost, Principal Component Analysis was applied, reducing the number of features from 136 to 35, by setting the desired explained variance to 99\% [3,4].

\begin{center}
\captionof{table}{List of all features extracted from voice signals.}
\label{table1} % for use in \ref{table1} - to refer to the table number
\begin{tabular}[c]{ |c| } 
 \hline
 \textbf{Feature Name}  \\ [1ex]
 \hline
 Zero Crossing Rate \\ [0.5ex]
 Energy \\ [0.5ex]
 Entropy of Energy \\ [0.5ex]
 Spectral Centroid  \\ [0.5ex]
 Spectral Spread \\ [0.5ex]
 Spectral Entropy \\ [0.5ex]
 Spectral Flux \\ [0.5ex]
 Spectral Rolloff \\ [0.5ex]
 12 Mel Frequency Cepstral Coefficients \\ [0.5ex]
 11 Chroma Vectors \\ [0.5ex]
 Chroma Deviation \\ [0.5ex]
 \hline
\end{tabular}
\end{center}

\vspace{2mm}
\textbf{ B. Feature Selection }\par

\vspace{2mm}
\textbf{ C. Defining Classification Groups }\par
Explain how we divided age and identity groups and why we separated native vs English utterances. 

\vspace{2mm}
\textbf{ C. Dataset Split }\par
Explain the 10 nested hold outs and why we did that.

\vspace{2mm}
\textbf{III. Experiments, Results and Discussion }\par

\vspace{2mm}
\textbf{ A. Gender Classification }\par

\vspace{2mm}
\textbf{ B. Age Classification }\par

\vspace{2mm}
\textbf{ C. Performance of Native vs Second Language }\par

\vspace{2mm}
\textbf{ D. Identification of Specific Individual in Subset }\par

\vspace{2mm}
\textbf{IV. Conclusion }\par


\vspace{2mm}
\textbf{V. References}\par
[1]	O. Iloanusi et al., Voice Recognition and Gender Classification in the Context of Native Languages and Lingua Franca. 2019, pp. 175-179.\par
[2] Rami S. Alkhawaldeh, "DGR: Gender Recognition of Human Speech Using One-Dimensional Conventional Neural Network", Scientific Programming, vol. 2019, 12 pages, 2019.
[3] https://www.mikulskibartosz.name/pca-how-to-choose-the-number-of-components/
[4] https://medium.com/datadriveninvestor/principal-component-analysis-pca-a0c5715bc9a2
\end{document}